# 🧪 SQL PRACTICE SCRIPTS

This repository contains a structured set of **PySpark practice scripts** designed to help data engineers, analysts, and enthusiasts build a solid foundation in distributed data processing using Apache Spark.

## 🚀 What's Inside?

- RDD operations (map, filter, reduce, actions)
- DataFrame creation and schema management
- Column-level transformations (`withColumn`, `drop`, `alias`)
- Aggregations and grouping (`groupBy`, `agg`)
- Joins (inner, left, right, full)
- PySpark SQL queries and temporary views
- Handling nulls, duplicates, and complex data types
- Performance tuning and best practices
- Bonus: Real-world scenarios & mini ETL simulations

## 🧰 Technologies Used

- PySpark (Apache Spark 3.x+)
- Python 3.x
- Local mode / EMR-ready scripts
- Optional: Integration-ready for S3, Snowflake, and Airflow

---

## ✅ Ideal For

- Students preparing for Spark interviews
- Professionals transitioning to big data engineering roles
- Practicing real-world transformations on sample datasets
- Pairing with Airflow or EMR for orchestration practice

---

Feel free to fork, clone, and enhance with your own examples! 🔁
